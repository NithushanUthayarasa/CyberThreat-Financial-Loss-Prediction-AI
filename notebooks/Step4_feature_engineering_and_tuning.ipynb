{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b2faf13-2e94-452e-8be6-92c376b17e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning CatBoost...\n",
      "Best params: {'model__learning_rate': 0.05, 'model__iterations': 500, 'model__depth': 10}\n",
      "CatBoost -> RMSE: 4.66, MAE: 1.96, R²: 0.9731\n",
      "\n",
      "Tuning LightGBM...\n",
      "Best params: {'model__n_estimators': 200, 'model__max_depth': 10, 'model__learning_rate': 0.1}\n",
      "LightGBM -> RMSE: 3.54, MAE: 1.64, R²: 0.9845\n",
      "\n",
      "Tuning RandomForest...\n",
      "Best params: {'model__n_estimators': 100, 'model__max_depth': 10}\n",
      "RandomForest -> RMSE: 4.76, MAE: 1.90, R²: 0.9720\n",
      "\n",
      "Tuning GradientBoosting...\n",
      "Best params: {'model__n_estimators': 200, 'model__max_depth': 3, 'model__learning_rate': 0.1}\n",
      "GradientBoosting -> RMSE: 4.30, MAE: 2.15, R²: 0.9772\n",
      "\n",
      "Tuning XGBoost...\n",
      "Best params: {'model__subsample': 0.8, 'model__n_estimators': 200, 'model__max_depth': 7, 'model__learning_rate': 0.1}\n",
      "XGBoost -> RMSE: 4.00, MAE: 1.53, R²: 0.9802\n",
      "\n",
      "Step 4 (5 models tuned) completed successfully!\n",
      "Results saved at: C:\\Users\\uthay\\Desktop\\CyberThreats_FinancialLoss_Prediction_ML\\data\\processed\\model_results_step4.csv\n",
      "Models saved in: C:\\Users\\uthay\\Desktop\\CyberThreats_FinancialLoss_Prediction_ML\\models\n"
     ]
    }
   ],
   "source": [
    "# Step4_feature_engineering_and_tuning.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# ---------------------------\n",
    "# Suppress warnings globally\n",
    "# ---------------------------\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Also silence joblib loky backend warnings\n",
    "import joblib\n",
    "joblib.parallel_backend('loky', inner_max_num_threads=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# ---------------------------\n",
    "# Paths\n",
    "# ---------------------------\n",
    "RAW_DATA_PATH = r\"C:\\Users\\uthay\\Desktop\\CyberThreats_FinancialLoss_Prediction_ML\\data\\raw\\Global_Cybersecurity_Threats_2015-2024 (1).csv\"\n",
    "PROCESSED_PATH = r\"C:\\Users\\uthay\\Desktop\\CyberThreats_FinancialLoss_Prediction_ML\\data\\processed\"\n",
    "MODEL_PATH = r\"C:\\Users\\uthay\\Desktop\\CyberThreats_FinancialLoss_Prediction_ML\\models\"\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "\n",
    "# ---------------------------\n",
    "# Load dataset\n",
    "# ---------------------------\n",
    "df = pd.read_csv(RAW_DATA_PATH)\n",
    "\n",
    "# ---------------------------\n",
    "# Feature engineering\n",
    "# ---------------------------\n",
    "numeric_features = ['Number of Affected Users', 'Incident Resolution Time (in Hours)']\n",
    "categorical_features = ['Attack Type', 'Target Industry', 'Attack Source', 'Security Vulnerability Type']\n",
    "target = 'Financial Loss (in Million $)'\n",
    "\n",
    "df['AttackType_TargetIndustry'] = df['Attack Type'] + \"_\" + df['Target Industry']\n",
    "categorical_features.append('AttackType_TargetIndustry')\n",
    "\n",
    "df['Loss_per_User'] = df[target] / (df['Number of Affected Users'] + 1)\n",
    "numeric_features.append('Loss_per_User')\n",
    "\n",
    "X = df[numeric_features + categorical_features]\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ---------------------------\n",
    "# Preprocessing\n",
    "# ---------------------------\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# ---------------------------\n",
    "# Models + hyperparameter grids (5 models only)\n",
    "# ---------------------------\n",
    "models_params = {\n",
    "    \"CatBoost\": (\n",
    "        Pipeline([('preprocessor', preprocessor),\n",
    "                  ('model', CatBoostRegressor(verbose=0, random_state=42))]),\n",
    "        {\"model__depth\": [6, 8, 10],\n",
    "         \"model__learning_rate\": [0.05, 0.1],\n",
    "         \"model__iterations\": [200, 500]}\n",
    "    ),\n",
    "    \"LightGBM\": (\n",
    "        Pipeline([('preprocessor', preprocessor),\n",
    "                  ('model', LGBMRegressor(random_state=42, verbose=-1))]),\n",
    "        {\"model__n_estimators\": [100, 200],\n",
    "         \"model__max_depth\": [5, 10, -1],\n",
    "         \"model__learning_rate\": [0.05, 0.1]}\n",
    "    ),\n",
    "    \"RandomForest\": (\n",
    "        Pipeline([('preprocessor', preprocessor),\n",
    "                  ('model', RandomForestRegressor(random_state=42))]),\n",
    "        {\"model__n_estimators\": [100, 200],\n",
    "         \"model__max_depth\": [10, 20, None]}\n",
    "    ),\n",
    "    \"GradientBoosting\": (\n",
    "        Pipeline([('preprocessor', preprocessor),\n",
    "                  ('model', GradientBoostingRegressor(random_state=42))]),\n",
    "        {\"model__n_estimators\": [100, 200],\n",
    "         \"model__learning_rate\": [0.05, 0.1],\n",
    "         \"model__max_depth\": [3, 5]}\n",
    "    ),\n",
    "    \"XGBoost\": (\n",
    "        Pipeline([('preprocessor', preprocessor),\n",
    "                  ('model', XGBRegressor(random_state=42, verbosity=0))]),\n",
    "        {\"model__n_estimators\": [100, 200],\n",
    "         \"model__max_depth\": [5, 7],\n",
    "         \"model__learning_rate\": [0.05, 0.1],\n",
    "         \"model__subsample\": [0.8, 1.0]}\n",
    "    )\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# ---------------------------\n",
    "# Train, tune, evaluate\n",
    "# ---------------------------\n",
    "for name, (pipeline, params) in models_params.items():\n",
    "    print(f\"\\nTuning {name}...\")\n",
    "    search = RandomizedSearchCV(\n",
    "        pipeline,\n",
    "        param_distributions=params,\n",
    "        n_iter=min(10, len(params)),\n",
    "        cv=3,\n",
    "        scoring='r2',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    search.fit(X_train, y_train)\n",
    "    best_model = search.best_estimator_\n",
    "    best_params = search.best_params_\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Best params:\", best_params)\n",
    "    print(f\"{name} -> RMSE: {rmse:.2f}, MAE: {mae:.2f}, R²: {r2:.4f}\")\n",
    "\n",
    "    results[name] = {\"RMSE\": rmse, \"MAE\": mae, \"R2\": r2}\n",
    "    joblib.dump(best_model, os.path.join(MODEL_PATH, f\"{name}_tuned.joblib\"))\n",
    "\n",
    "# ---------------------------\n",
    "# Save results\n",
    "# ---------------------------\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_file = os.path.join(PROCESSED_PATH, \"model_results_step4.csv\")\n",
    "results_df.to_csv(results_file, index=True)\n",
    "\n",
    "print(f\"\\nStep 4 (5 models tuned) completed successfully!\")\n",
    "print(f\"Results saved at: {results_file}\")\n",
    "print(f\"Models saved in: {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c205a4-47a7-4359-a507-334ee65fe90d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
