# ğŸ” Cyber Threats & Financial Loss Prediction (2015â€“2024)

An **end-to-end machine learning system** to predict **financial losses caused by cybersecurity threats**.  
This project implements a **complete Step-by-Step ML pipeline (Step 1 â†’ Step 10)**, starting from raw data cleaning and ending with **automated best-model deployment**.

---

## ğŸ“Œ Project Overview

Cybersecurity incidents are increasing globally, causing **significant financial damage across industries**.  
Organizations struggle to quantify potential losses due to complex factors such as **attack type, vulnerabilities, and incident resolution time**.

This project addresses that challenge by building a **production-ready ML pipeline** that predicts financial loss exposure from cyber attacks.

---

## â“ Problem Statement

Estimating financial losses from cyber attacks is difficult due to:
- Diverse attack types  
- Varying resolution times  
- Industry-specific vulnerabilities  

Without accurate prediction, organizations risk:
- Poor resource allocation  
- Ineffective incident response  
- Underinvestment or overinvestment in security measures  

---

## ğŸ¯ Purpose & Objectives

The goal is to predict **financial loss (in million USD)** from cyber attacks using structured data and machine learning, enabling:

- ğŸ” Proactive cyber-risk assessment  
- ğŸ“Š Better resource allocation  
- ğŸ­ Industry-specific cyber-risk profiling  
- ğŸ’° Data-driven security investment decisions  

---

## ğŸ§¾ Dataset & Features

**Source:** Kaggle â€” *Global Cybersecurity Threats (2015â€“2024)*  
**Records:** ~3,000 cybersecurity incidents  
**Original Features:** 10 columns  

### Key Original Columns
- Country  
- Year  
- Attack Type  
- Target Industry  
- Financial Loss *(target variable)*  
- Number of Affected Users  
- Attack Source  
- Security Vulnerability Type  
- Defense Mechanism Used  
- Incident Resolution Time  

### ğŸ”§ Engineered Features
- **Loss_per_User** = Financial Loss Ã· Number of Affected Users  
- **AttackType_TargetIndustry** (interaction feature)

> âš¡ After encoding categorical variables, the final model uses **~20â€“30 input features**.

---

## ğŸ”„ End-to-End ML Pipeline (Step 1 â†’ Step 10)

1. Feature Selection & Data Cleaning  
2. Preprocessing Pipeline (scaling, encoding, train-test split)  
3. Baseline Model Training  
4. Feature Engineering & Hyperparameter Tuning  
5. Classification Framing (High-Risk Loss Detection)  
6. Baseline vs Tuned Model Comparison  
7. Visual Performance Analysis  
8. Feature Importance Analysis  
9. Model Benchmarking & Variance Check  
10. Final Model Deployment  

---

## ğŸ§  Feature Engineering & Preprocessing

- Removed irrelevant features  
- Handled missing values:
  - Median for numeric features  
  - Mode for categorical features  
- Dropped duplicate records  
- Created interpretable interaction features  

---

## ğŸ§ª Machine Learning Models Used

- Random Forest  
- Gradient Boosting  
- XGBoost  
- LightGBM  
- CatBoost  

---

## ğŸ” Evaluation Metrics

### Regression Metrics
- RMSE  
- MAE  
- RÂ² Score  

### Classification Metrics (High-Risk Loss Detection)
- Accuracy  
- Precision  
- Recall  
- F1-Score  
- ROCâ€“AUC  

---

## ğŸ“Š Results Summary

| Step | Description | Model / Metrics | Notes |
|----|------------|----------------|------|
| 3 | Baseline Training | Negative RÂ² | Underfitting |
| 4 | Feature Engineering + Tuning | **LightGBM:** RMSE=3.54, MAE=1.64, RÂ²=0.985 | Best performance |
| 5 | Classification Framing | Accuracy=0.97, F1=0.94, ROCâ€“AUC=0.995 | High-risk detection |
| 6 | Baseline vs Tuned | Tuned RÂ² â‰ˆ 0.97â€“0.98 | Massive improvement |
| 8 | Feature Importance | Loss_per_User, Resolution Time | Key drivers |
| 9 | Model Benchmarking | See table below | Generalization check |

---

## ğŸ“ˆ Model Benchmarking

| Model | Train RÂ² | Test RÂ² | Diagnosis |
|-----|---------|--------|----------|
| LightGBM | 0.993 | 0.985 | âœ… Good generalization |
| XGBoost | 0.9998 | 0.980 | âš  High variance |
| Gradient Boosting | 0.996 | 0.977 | âœ… Good generalization |
| CatBoost | 0.999 | 0.973 | âš  High variance |
| Random Forest | 0.989 | 0.972 | âœ… Good generalization |

**Inference Time:** ~0.02 seconds per batch

---

## ğŸ›  Handling High Variance

- Regularization (`reg_lambda`, `reg_alpha`, `l2_leaf_reg`)  
- Reduced model complexity (`max_depth`, `n_estimators`)  
- k-Fold Cross-Validation  
- Feature selection to remove noisy features  
- Dataset expansion / augmentation  

---

## ğŸš€ Deployment (Step 10)

- âœ… Best model: **LightGBM**
- ğŸ’¾ Saved as: `models/production_model.joblib`
- ğŸ” Reusable prediction function
- â™»ï¸ Fully reproducible pipeline for real-world use

---

## ğŸ“ Project Structure

```text
CyberThreats_FinancialLoss_Prediction_ML/
â”‚â”€â”€ data/
â”‚   â”œâ”€â”€ raw/          # Original dataset CSVs
â”‚   â”œâ”€â”€ interim/      # Cleaned & selected features
â”‚   â””â”€â”€ processed/    # Step-wise processed data
â”‚
â”‚â”€â”€ notebooks/        # Step 1 â†’ Step 10 notebooks
â”‚â”€â”€ models/           # Trained models (.joblib)
â”‚â”€â”€ reports/          # Reports & analysis
â”‚â”€â”€ outputs/          # Images & pipelines
â”‚â”€â”€ plots/            # Feature importance plots
â”‚â”€â”€ README.md
â”‚â”€â”€ requirements.txt
```

##ğŸ”§ How to Run

git clone https://github.com/NithushanUthayarasa/CyberThreat-Financial-Loss-Prediction-AI
cd CyberThreats_FinancialLoss_Prediction_ML
pip install -r requirements.txt
jupyter notebook


â¡ï¸ Run notebooks Step 1 â†’ Step 10 sequentially

##ğŸŒ Business & Social Impact

Cybersecurity risk assessment
Financial loss forecasting
Incident response prioritization
Industry-specific cyber-risk profiling
Data-driven security investment decisions

##ğŸŒŸ Highlights

âœ… Full production-ready ML pipeline
ğŸ“ˆ RÂ² = 0.985, ROCâ€“AUC = 0.995
ğŸ” Interpretable features improve insights
âš™ï¸ High-variance models analyzed & mitigated
ğŸ” Fully reproducible and deployable

##ğŸ›  Tech Stack
Python
Pandas, NumPy
Scikit-Learn
LightGBM, XGBoost, CatBoost
Matplotlib, Seaborn
Jupyter Notebook

##ğŸ‘¤ Author

Nithushan Uthayarasa
Machine Learning | Cybersecurity Analytics
